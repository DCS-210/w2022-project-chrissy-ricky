---
title: "Covid-19 and Making Predictions"
subtitle:
author: "Chrissy Aman and Ricky Sun"
institute: "Bates College"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    css: xaringan-themer2.css
    lib_dir: libs
    nature:
      ratio: "16:9"
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false

#xaringan::inf_mr()
#accessible colors: scale_color_viridis_d() 
---

```{r load-packages, include = FALSE}
library(tidyverse)
library(tidymodels)
library(reshape2)
library(palmerpenguins)
library(knitr)
library(tmap)
library(tmaptools)
library(sf)
library(leaflet)
library(xaringanthemer)
library(rgdal)
library(plm)       # Panel data analysis library
library(car)       # Companion to applied regression 
library(gplots)    # Various programing tools for plotting data
library(tseries)   # For timeseries analysis
library(lmtest)    # For hetoroskedasticity analysis
library(dygraphs)
library(xts) # To make the convertion data-frame / xts format
library(forecast)
library(rddtools)
library(magrittr)
library(class)
library(gmodels)
```

```{r setup, include=FALSE}
# For better figure resolution
knitr::opts_chunk$set(fig.retina = 3, dpi = 300, fig.width = 6, fig.asp = 0.618, out.width = "80%")
```

```{r load-data, include=FALSE}
# Load your data here
covid_data <- readr::read_csv(file = "../data/owid-covid-data.csv")
covid_data <- covid_data %>%
  mutate(year = format(date, format="%Y")) %>%
  mutate(month = format(date, format="%m")) %>%
  mutate(day = format(date, format="%d")) 
```

```{r title-page-pic, include=FALSE}
style_xaringan(
  title_slide_background_image = "img/covid.jpg"
)
```

## Outline 

<style type="text/css">
.remark-slide-content {
    font-size: 30px;
    padding: 1em 4em 1em 4em;
}
</style>

- Introduction

- Literature Review

- Our Data  

- Methods & Data Analyses

- Results

- Limitations and Potential Future Studies

---


class: inverse, center, middle

background-image: url("images/cool.png")

# Introduction

---

# Introduction 

COVID-19, also known as Coronavirus disease 2019 is a contagious disease caused by a virus, the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)

Up until yesterday, there are over 497,057,239 infections and 6,179,104 deaths since the beginning of the pandemic

Although no one can predict a pandemic like this, with the help of data, we might be able to use available data to, for example, evaluate risks, so that the virus and mutations can be better managed or even contained in earlier stages

---

## Research Question

- In our research, we are trying to use Covid-19 related data, together with other relevant
data to find potential predictors for Covid-19 cases, deaths, or vaccination rates. 

? Do vaccinations effectively mitigate the death rate 

? Are higher percentage of older people predicts higher death rate

? What about other variables in predicting Covid-19

? Can we implement machine learning algorithm to predict Covid-19



---

class: inverse, middle, center

# Literature Review

---

# [1a] Covid-19 severity

.pull-left[
```{r severity, echo = FALSE, out.width = "60%", fig.align = "center", fig.cap = "Reference: Mulinari T.O., et al. (2020) MDPI"}
include_graphics("https://www.mdpi.com/pathogens/pathogens-09-00817/article_deploy/html/images/pathogens-09-00817-g001-550.jpg")
```
]
.pull-right[
- The unpredictability of the progression of coronavirus disease 2019 (COVID-19) may be attributed to the low precision of the tools used to predict the prognosis of this disease, especially when the virus is mutating in a fast speed from alpha, to Omicron, and there are more recent variants too
]


---

# [1b] vitamin D and covid-19
.pull-left[
```{r vitaminD, echo = FALSE, out.width = "100%", fig.align = "center", fig.cap = "Reference: Meltzer DO, et al. (2021) JAMA Netw Open"}
include_graphics("https://www.healio.com/~/media/slack-news/fm_im/misc/infographics/2020/september/pc0920meltzer_graphic_01.jpg?h=630&w=1200&la=en&hash=AA5CE3037B8695511804123FBF351C92")
```
]
.pull-right[
- Several studies suggest an association between serum 25-hydroxyvitamin D (25OHD) and the likelihood of suffering severe symptoms of covid-19
]


---

# [2] Covid-19 and weather
.pull-left[
- Akin to respiratory tract infection diseases, climatic conditions may significantly influence the COVID-19 pandemic, significant efforts have been made to explore the relationship between climatic condition and growth in number of COVID-19 cases 
]
.pull-right[
```{r weather, echo = FALSE, out.width = "80%", fig.align = "center", fig.cap = "Reference: Mesay Moges Menebo (2020)"}
include_graphics("https://ars.els-cdn.com/content/image/1-s2.0-S004896972033179X-ga1.jpg")
```
]

---

# [3] Covid-19 and social media
.pull-left[
- Social media data from, for example, google search, twitter, facebook and other social media platforms, may also be used to develop models and as early warning signals of COVID-19 outbreaks. Social media data can also presents with people's perception of risks 
and general mental states 
]
.pull-right[
```{r social, echo = FALSE, out.width = "80%", fig.align = "center", fig.cap = "Reference: JHU Hub (2020)"}
include_graphics("https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_2400/public/social_media_032720.jpg?itok=oJE4T6Tf")
```
]

---

# [4] COVID-19 and impacts
.pull-left[
```{r impacts, echo = FALSE, out.width = "100%", fig.align = "center", fig.cap = "Reference: James G. (2020)"}
include_graphics("https://cdn-japantimes.com/wp-content/uploads/2020/03/np_file_1549.jpeg")
```
]
.pull-right[
- Covid-19 also has had great impacts in our daily lives (racial issues, job markets, also economic activities, and so on)
]

---

# [5] Covid-19 and machine learning
.pull-left[
```{r ML, echo = FALSE, out.width = "100%", fig.align = "center", fig.cap = "Reference: Suchandrima Bhowmik (2021)"}
include_graphics("https://www.news-medical.net/image.axd?picture=2021%2F12%2Fshutterstock_1722032125.jpg")
```
]
.pull-right[
- Developing accurate forecasting tools will help fighting against the pandemic. Prediction models that combine several features to estimate the risk of infection aim to assist medical staff worldwide in helping patients, especially in the context of limited healthcare resources
]
---

class: inverse, middle, center

# Data

---

## Data - details

The dataset is coming from "Our World in Data" Covid-19 public data, together with data from JHU, WHO, CDC and World Bank. The data covers a wide range:

- Basic Covid-19 data (cases, deaths)
- Hospital & ICU (ICU beds, ICU patients)
- Policy responses (stringency_index)
- Health info (Reproduction rate, diabetes prevalence)
- Tests & positivity
- Vaccinations
- Others (populations, life_expectancy, GDP per catpita and so on)

---

class: inverse, middle, center

# Methods & Data Analyses

---

# Methods & Data Analyses - details

Part I: Preliminary exploration like summary statistics, scatter plots, correlations, maps

Part II: Regression analyses, ranging from OLS, fixed effects, to regression continuity

Part III: time series (ARiMA) and machine learning algorithm(s)

---

class: inverse, middle, center

# Results & Implications 

---

# HDI & Death Rate
.pull-left[
```{r read_shape, include=FALSE}
worldshape <- readOGR( 
  dsn= ("/cloud/project/data/world_shape_file/"), 
  layer="TM_WORLD_BORDERS-0.3",
  verbose=FALSE)

worldshape2 <- st_read("/cloud/project/data/world_shape_file/TM_WORLD_BORDERS-0.3.shp")
```

```{r HDI-map, echo = FALSE, warning = FALSE, message=FALSE}
HDI <- covid_data %>%
  filter(date == "2022-02-20") %>%
  filter(is.na(continent) == FALSE) %>%
  select(iso_code, location, date, human_development_index) %>%
  na.omit()

hdi_map <- HDI %>% 
  left_join(worldshape2, by = c("location" = "NAME")) %>%
  st_as_sf()

pal2 <- colorNumeric(palette = "RdYlGn", domain = hdi_map$human_development_index)
labels <- sprintf("<strong>%s</strong><br/>%s ", hdi_map$location, hdi_map$human_development_index) %>%
  lapply(htmltools::HTML)

h_map <- leaflet(data = hdi_map) %>% 
  addTiles()  %>% 
  setView(lat=10, lng=0 , zoom=1.5) %>%
  addPolygons(fillColor = ~pal2(hdi_map$human_development_index),
                                 fillOpacity = 1, 
                                 color = "white",
                                 opacity = 0.7,
                                 weight = 1,
                                 label = labels) %>%
  leaflet::addLegend("bottomleft", pal = pal2, values = ~hdi_map$human_development_index,
    title = "Human Development Index",
    opacity = 1)

h_map
```
]
.pull-right[
```{r death-map, echo = FALSE, warning = FALSE, message=FALSE}
death <- covid_data %>%
  filter(date == "2022-02-18") %>%
  filter(is.na(continent) == FALSE) %>%
  mutate(death_rate = total_deaths/total_cases) %>%
  select(iso_code, location, date, death_rate) %>%
  na.omit()

death_map <- death %>% 
  left_join(worldshape2, by = c("location" = "NAME")) %>%
  st_as_sf()

pal2 <- colorNumeric(palette = "RdYlGn", domain = death_map$death_rate)
labels <- sprintf("<strong>%s</strong><br/>%s ", death_map$location, death_map$death_rate) %>%
  lapply(htmltools::HTML)

d_map <- leaflet(data = death_map) %>% 
  addTiles()  %>% 
  setView( lat=10, lng=0 , zoom=1) %>%
  addPolygons(fillColor = ~pal2(death_map$death_rate),
                                 fillOpacity = 1, 
                                 color = "white",
                                 opacity = 1,
                                 weight = 1,
                                 label = labels) %>%
  leaflet::addLegend("bottomleft", pal = pal2, values = ~ death_map$death_rate,
    title = "Death Rate",
    opacity = 1)

d_map
```
]


---

# HDI & Total Cases

.pull-left[
```{r development, echo = FALSE, warning=FALSE}
development <- covid_data %>%
  filter(date == "2022-02-20") %>%
  filter(is.na(continent) == FALSE) %>%
  select(location, human_development_index) %>%
  arrange(desc(human_development_index)) %>%
  top_n(10)

development
```
]
.pull-right[
```{r total_cases, echo = FALSE,warning=FALSE}
t_cases <- covid_data %>%
  filter(date == "2022-02-20") %>%
  filter(is.na(continent) == FALSE) %>%
  select(location, total_cases) %>%
  arrange(desc(total_cases)) %>%
  top_n(10)

t_cases
```
]

---

# Vaccination & Death Rate

.pull-left[
```{r vaccination, echo = FALSE,warning=FALSE}
vac <- covid_data %>%
  filter(date == "2022-02-20") %>%
  filter(is.na(continent) == FALSE) %>%
  mutate(vaccination = people_fully_vaccinated/population) %>%
  select(location, vaccination) %>%
  arrange(desc(vaccination)) %>%
  top_n(10)

vac
```
]
.pull-right[
```{r death, echo = FALSE,warning=FALSE}
death <- covid_data %>%
  filter(date == "2022-02-20") %>%
  filter(is.na(continent) == FALSE) %>%
  mutate(death_rate = total_deaths/total_cases) %>%
  select(location, death_rate) %>%
  arrange(desc(death_rate)) %>%
  top_n(10)

death
```
]


---

# Correlations

```{r correlation_heatmap, echo = FALSE}
covid_heat <- covid_data %>%
  filter(date == "2022-02-20") %>%
  filter(is.na(continent) == FALSE) %>%
  mutate(smoker = female_smokers + male_smokers) %>%
  mutate(vaccination = people_fully_vaccinated/population) %>%
  mutate(boosters = total_boosters/population) %>%
  select(vaccination, total_cases_per_million, total_deaths_per_million, boosters, population_density, stringency_index, aged_70_older, gdp_per_capita, hospital_beds_per_thousand,smoker, human_development_index) %>%
  na.omit()
  
cormat <- round(cor(covid_heat),2)

melted_cormat <- melt(cormat)

ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile() +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab",
                       name="Pearson\nCorrelation") +
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 10, hjust = 1))+
  coord_fixed()
```

---

# HDI & Vaccination

```{r vaccination-HDI, echo = FALSE, warning = FALSE, message=FALSE, fig.alt = "scatterplot of flipper length by bill length of 3 penguin species, where we show penguins with bigger flippers have bigger bills"}
covid_data %>%
  filter(date == "2022-02-20") %>%
  filter(is.na(continent) == FALSE) %>%
  mutate(smoker = female_smokers + male_smokers) %>%
  mutate(vaccination_rate = people_fully_vaccinated/population) %>%  
  mutate(booster = total_boosters/population) %>%
  ggplot(mapping = aes(x = vaccination_rate, 
                       y = human_development_index)) +
  geom_point(size = 2, mapping = aes()) +
  labs(title = "vaccination rate vs. human development index", 
       subtitle = "xx",
       x = "vaccination rate",
       y = "human development index") +
  scale_color_viridis_d() +
  geom_smooth(color = "blue") 
```

---

# Vaccination & Death Rate
```{r vac-death, echo = FALSE, warning = FALSE, message=FALSE}
covid_data %>%
  filter(date == "2022-02-20") %>%
  filter(is.na(continent) == FALSE) %>%
  mutate(smoker = female_smokers + male_smokers) %>%
  mutate(vaccination_rate = people_fully_vaccinated/population) %>%  
  mutate(death = total_deaths/total_cases) %>%  
  mutate(booster = total_boosters/population) %>%
  ggplot(mapping = aes(x = vaccination_rate, 
                       y = death)) +
  geom_point(size = 1, mapping = aes()) +
  labs(title = "percentage death of population vs. diabetes prevalence", 
       subtitle = "xx",
       x = "percentage death of population",
       y = "diabetes prevalence") +
  scale_color_viridis_d() +
  geom_smooth(color = "blue") 
```

---

# Linear Model [omicron]

```{r linear-model-1, echo = FALSE}
covid_total <- covid_data %>%
  filter(date == "2022-02-20")

covid_country <- covid_total %>%
  filter(is.na(continent) == FALSE) %>%
  mutate(vaccination = people_fully_vaccinated/population) %>%
  mutate(booster = total_boosters/population) %>%
  mutate(death_norm = (total_deaths_per_million - mean(total_deaths_per_million)) /   sd(total_deaths_per_million)) 
  
covid_other <- covid_total %>%
  filter(is.na(continent) == TRUE)

reg1 <- linear_reg() %>%
  set_engine("lm") %>%
  fit(total_deaths_per_million ~ vaccination + stringency_index + handwashing_facilities + gdp_per_capita, data = covid_country) 

reg1 %>%
  tidy()
glance(reg1)$r.squared
glance(reg1)$adj.r.squared
```

---

# Linear Model [omicron]
```{r linear-model-2, echo = FALSE}
covid_total <- covid_data %>%
  filter(date == "2021-03-20")

covid_country <- covid_total %>%
  filter(is.na(continent) == FALSE) %>%
  mutate(vaccination = people_fully_vaccinated/population) %>%
  mutate(booster = total_boosters/population) %>%
  mutate(death_norm = (total_deaths_per_million - mean(total_deaths_per_million)) /   sd(total_deaths_per_million)) 
  
covid_other <- covid_total %>%
  filter(is.na(continent) == TRUE)

reg1 <- linear_reg() %>%
  set_engine("lm") %>%
  fit(total_deaths_per_million ~ vaccination + stringency_index + handwashing_facilities + gdp_per_capita, data = covid_country) 

reg1 %>%
  tidy()
glance(reg1)$r.squared
glance(reg1)$adj.r.squared
```

---

# Important Dates

Covid-19 Alpha: 31 December 2019 (January 22, 2020)

Covid-19 Delta: 1 December 2020

Covid-19 Omicron: 1 November, 2021

-----------

Vaccination: 13 December, 2020

Booster: 13 August, 2021

---


# # Linear Model [Delta]

```{r linear-model-3, echo = FALSE}
covid_total <- covid_data %>%
  filter(date == "2022-02-20")

covid_country <- covid_total %>%
  filter(is.na(continent) == FALSE) %>%
  mutate(vaccination = people_fully_vaccinated/population) %>%
  mutate(booster = total_boosters/population) %>%
  mutate(death_norm = (total_deaths_per_million - mean(total_deaths_per_million)) /   sd(total_deaths_per_million)) 
  
covid_other <- covid_total %>%
  filter(is.na(continent) == TRUE)

reg1 <- linear_reg() %>%
  set_engine("lm") %>%
  fit(total_deaths_per_million ~ vaccination + stringency_index + handwashing_facilities + gdp_per_capita, data = covid_country) 

reg1 %>%
  tidy()
glance(reg1)$r.squared
glance(reg1)$adj.r.squared
```

---

# # Linear Model [Alpha]
```{r linear-model-4, echo = FALSE}
covid_total <- covid_data %>%
  filter(date == "2021-03-20")

covid_country <- covid_total %>%
  filter(is.na(continent) == FALSE) %>%
  mutate(vaccination = people_fully_vaccinated/population) %>%
  mutate(booster = total_boosters/population) %>%
  mutate(death_norm = (total_deaths_per_million - mean(total_deaths_per_million)) /   sd(total_deaths_per_million)) 
  
covid_other <- covid_total %>%
  filter(is.na(continent) == TRUE)

reg1 <- linear_reg() %>%
  set_engine("lm") %>%
  fit(total_deaths_per_million ~ vaccination + stringency_index + handwashing_facilities + gdp_per_capita, data = covid_country) 

reg1 %>%
  tidy()
glance(reg1)$r.squared
glance(reg1)$adj.r.squared
```

---

# # Linear Model [Vaccination]
```{r linear-model-5, echo = FALSE}
covid_total <- covid_data %>%
  filter(date == "2021-03-20")

covid_country <- covid_total %>%
  filter(is.na(continent) == FALSE) %>%
  mutate(vaccination = people_fully_vaccinated/population) %>%
  mutate(booster = total_boosters/population) %>%
  mutate(death_norm = (total_deaths_per_million - mean(total_deaths_per_million)) /   sd(total_deaths_per_million)) 
  
covid_other <- covid_total %>%
  filter(is.na(continent) == TRUE)

reg1 <- linear_reg() %>%
  set_engine("lm") %>%
  fit(total_deaths_per_million ~ vaccination + stringency_index + handwashing_facilities + gdp_per_capita, data = covid_country) 

reg1 %>%
  tidy()
glance(reg1)$r.squared
glance(reg1)$adj.r.squared
```
---

# # Linear Model [Boosters]
```{r linear-model-6, echo = FALSE}
covid_total <- covid_data %>%
  filter(date == "2021-03-20")

covid_country <- covid_total %>%
  filter(is.na(continent) == FALSE) %>%
  mutate(vaccination = people_fully_vaccinated/population) %>%
  mutate(booster = total_boosters/population) %>%
  mutate(death_norm = (total_deaths_per_million - mean(total_deaths_per_million)) /   sd(total_deaths_per_million)) 
  
covid_other <- covid_total %>%
  filter(is.na(continent) == TRUE)

reg1 <- linear_reg() %>%
  set_engine("lm") %>%
  fit(total_deaths_per_million ~ vaccination + stringency_index + handwashing_facilities + gdp_per_capita, data = covid_country) 

reg1 %>%
  tidy()
glance(reg1)$r.squared
glance(reg1)$adj.r.squared
```
---

```{r time-table1, echo = FALSE, warning=FALSE, out.width="100%", out.height="80%"}
covid_time <- covid_data %>%
  select(location, date, total_cases) %>%
  filter(location == c("India", "Brazil", "France", "Germany", "Italy", "Mexico", "Russia", "United Kingdom", "United States"))

covid_time_wide <- pivot_wider(data = covid_time,
                                names_from = location,
                                values_from = total_cases)

don = xts(x = covid_time_wide[,-1], order.by = covid_time_wide$date)

p <- dygraph(don)
p
```

---

# ARiMA (Time Series)

---

```{r ARiMA_0, echo = FALSE, warning=FALSE, message = FALSE}
library(TTR)
covid_time <- covid_data %>%
  filter(location == "United States") %>%
  select(date, new_cases) %>%
  na.omit()
```

```{r ARiMA_1a, echo = FALSE, warning=FALSE, message = FALSE, out.width="90%", out.height="40%"}

ggplot(data = covid_time, aes(x = date, y = new_cases)) +
      geom_line(stat = "identity", fill = "purple") +
      labs(title = "New Covid-19 cases in United States",
           subtitle = "by time",
           x = "Date", y = "New cases") +
      theme_minimal()
```

---
```{r ARiMA_1b, echo = FALSE, warning=FALSE, message = FALSE, out.width="90%", out.height="40%"}
covid_time <- covid_time %>%
  mutate (cases_SMA = SMA(new_cases, n=8))

ggplot(data = covid_time, aes(x = date, y = cases_SMA)) +
      geom_line(stat = "identity", fill = "purple") +
      labs(title = "New Covid-19 cases in United States",
           subtitle = "by time",
           x = "Date", y = "New cases") +
      theme_minimal()
  
```

---
```{r ARiMA_2, echo=FALSE, warning=FALSE, message = FALSE, out.width="90%", out.height="90%"}
cases_diff <- diff(covid_time$new_cases, differences=1)
acf(cases_diff, lag.max=20)             
acf(cases_diff, lag.max=20, plot=FALSE) 
```

---
```{r ARiMA_3, echo=FALSE, warning=FALSE, message = FALSE, out.width="90%", out.height="90%"}
pacf(cases_diff, lag.max=20)             # plot a partial correlogram
pacf(cases_diff, lag.max=20, plot=FALSE) # get the partial autocorrelation values
```

---
```{r ARiMA_4, echo=FALSE, warning=FALSE, message = FALSE}
auto.arima(cases_diff)
```

```{r ARiMA_5, echo=FALSE, warning=FALSE, message = FALSE}
covid_time_arima <- arima(covid_time$new_cases, order=c(2,0,2)) 
covid_time_arima
```

---
# ARiMA Results
```{r ARiMA_6, echo=FALSE, warning=FALSE, message = FALSE, out.width="100%", out.height="90%"}
fit <- Arima(cases_diff, order=c(2,0,2))
```

```{r ARiMA_7, echo=FALSE, warning=FALSE, message = FALSE}
checkresiduals(fit)
```

---
# ARiMA (Forecasting)
```{r ARiMA8, echo=FALSE, warning=FALSE, message = FALSE}
autoplot(forecast(fit))
```
---

# Fixed Effects

Fixed effect

```{r make-dummy2}
#covid_data2 <- covid_data1 %>%
# select(vaccine_introduced, total_vaccinations, date, first_vaccination, interaction_term, #location, new_cases_per_million, weekly_hosp_admissions_per_million)
```

```{r make-dataset2}
#covid_data3 <- covid_data1 %>%
#  select(date, location, new_cases_per_million, weekly_hosp_admissions_per_million, people_fully_vaccinated_per_hundred,  new_deaths_per_million) %>% na.omit(people_fully_vaccinated_per_hundred, population_density, total_cases_per_million)
```

```{r make-covid-data-10}
#covid_data7 <- covid_data3 %>%
#  filter(location == "United States" | location == "United Kingdom" | location == "Canada" | location == "Belgium" | location == "Israel")
```

``` {r make-feregression}
#fixed.dum <-lm(weekly_hosp_admissions_per_million ~ people_fully_vaccinated_per_hundred + factor(location) - 1, data = covid_data7)
#summary(fixed.dum)

#yhat <- fixed.dum$fitted
#scatterplot(yhat ~ covid_data7$people_fully_vaccinated_per_hundred | covid_data7$location,  xlab ="people fully vaccinated per hundred", ylab ="covid cases", boxplots = FALSE, smooth = FALSE)
#abline(lm(covid_data7$weekly_hosp_admissions_per_million~covid_data7$people_fully_vaccinated_per_hundred),lwd=5, col="red")
```

---

# Regression Discontinuity (RDD)

```{r rdd1, echo=FALSE, warning=FALSE, message=FALSE}
rdd_data(y = covid_country$new_deaths_per_million, 
         x = covid_country$vaccination, 
         cutpoint = 0.1) %>% 
  rdd_reg_lm(slope = "separate") %>% 
  summary()
```

---
```{r rdd_plot1, echo=FALSE, warning=FALSE, message=FALSE}
covid_country %>%
  select(vaccination, new_deaths_per_million) %>%
  mutate(threshold = as.factor(ifelse(vaccination >= 0.1, 1, 0))) %>%
  ggplot(aes(x = vaccination, y = new_deaths_per_million, color = threshold)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  scale_color_brewer(palette = "Accent") +
  guides(color = FALSE) +
  geom_vline(xintercept = 0.1, color = "red",
    size = 1, linetype = "dashed") +
  labs(y = "New deaths (per million)",
       x = "Vaccination rate") +
  theme_minimal()
```

---
```{r rdd2, echo=FALSE, warning=FALSE, message=FALSE}
covid_total <- covid_data %>%
  filter(date == "2022-02-20")

covid_country <- covid_total %>%
  filter(is.na(continent) == FALSE) %>%
  mutate(vaccination = people_fully_vaccinated/population) %>%
  mutate(booster = total_boosters/population) %>%
  mutate(death_norm = (total_deaths_per_million - mean(total_deaths_per_million)) /   sd(total_deaths_per_million)) 

rdd_data(y = covid_country$new_deaths_per_million, 
         x = covid_country$vaccination, 
         cutpoint = 0.5) %>% 
  rdd_reg_lm(slope = "same") %>% 
  summary()
```

---
```{r rdd_plot2, echo=FALSE, warning=FALSE, message=FALSE}
covid_country %>%
  select(vaccination, new_deaths_per_million) %>%
  mutate(threshold = as.factor(ifelse(vaccination >= 0.5, 1, 0))) %>%
  ggplot(aes(x = vaccination, y = new_deaths_per_million, color = threshold)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  scale_color_brewer(palette = "Accent") +
  guides(color = FALSE) +
  geom_vline(xintercept = 0.5, color = "red",
    size = 1, linetype = "dashed") +
  labs(y = "New deaths (per million)",
       x = "Vaccination rate") +
  theme_minimal()
```

---

# Maching Learning

Machine learning algorithms can minimize forecasting error and do the forecast much faster and with the usage of more data. What's more, machine learning algorithms can analyze many alternative models at the same time, when in traditional econometrics you can analyze just one model at a time

---

# Maching Learning

1. logistic regression

2. KNN (clusters) &  K-Means Clustering

3. Random Forest

4. Support Vector Machine

5. Decision Trees

---

# Maching Learning (KNN)

What is KNN?

Let’s assume we have several groups of labeled samples. In our sample, this might be countries that do well in coping with Covid-19 and countries that did not do well. Now, suppose we have an unlabeled example which needs to be classified into one of the several labeled groups.

---

```{r knn1, echo=FALSE, warning=FALSE, message = FALSE}
knn_sample <- covid_data %>%
  filter(date == "2022-02-20") %>%
  mutate(death_rate = total_deaths/total_cases) %>%
  mutate(development = ifelse(human_development_index > 0.7225, "M", "L")) %>%
  select(development, total_cases, people_fully_vaccinated, total_boosters, population_density, aged_70_older, gdp_per_capita, cardiovasc_death_rate, hospital_beds_per_thousand, human_development_index) %>%
  na.omit()

knn_sample$development <- factor(knn_sample$development, levels = c("M", "L"), labels = c("more developed country", "less developed country"))

normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x))) }

knn_norm <- as.data.frame(lapply(knn_sample[2:10], normalize))

knn_train <- knn_norm[1:31,]
knn_test <- knn_norm[32:62,]

knn_train_labels <- knn_sample[1:31, 1]
knn_test_labels <- knn_sample[32:62, 1] 

knn_train <- as.data.frame(knn_train)
knn_train_labels <- as.data.frame(knn_train_labels)
knn_test_labels <- as.data.frame(knn_test_labels)
knn_test <- as.data.frame(knn_test)
cl = knn_train_labels[,1]
test = knn_test_labels[,1]

knn_test_pred <- knn(train = knn_train, test = knn_test, cl, k=7)
```

```{r knn2, echo=FALSE, warning=FALSE, message = FALSE, out.width="70%", out.height="40%"}
knn_one <- CrossTable(x = test, knn_test_pred, prop.chisq = FALSE)
```

```{r}
knn_one$t
```

---

class: inverse, middle, center

# Limitations and Potential Future Studies

---

# Limitations 

1. Data Point (county-level data)

2. Standardization of data

3. Mutations of Covid-19, types of vaccinations

4. Policies

5. Prediction at a global level may not be as useful

---

# Future Studies
1. Tracking recovery for children and elder population (sequelae, mental health)

2. Studying the transitioning in traditional industries (airlines, manufacturing)

3. Anti-trust activities during Covid-19

4. County level data

---

class: inverse, middle, center

# Thank you!

---

class: inverse, middle, center

# Q & A




